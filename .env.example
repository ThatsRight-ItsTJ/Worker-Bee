# This library uses chat_init_model from langchain_core.chat_models.base. It supports different models from different providers.
# Check https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html for more information.
# Here you should set the model, the provider and and all keys that are necessary for the provider.

# OPTION 1: Azure OpenAI (Recommended if you have access)
MODEL=gpt-4o
MODEL_PROVIDER=azure
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=

# OPTION 1b: Azure OpenAI with specific deployment
# AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o

# OPTION 2: OpenAI (if you have OpenAI API key)
# MODEL=gpt-4o
# MODEL_PROVIDER=openai
# OPENAI_API_KEY=

# OPTION 3: Anthropic Claude (if you have Anthropic API key)
# MODEL=claude-3-5-sonnet-20241022
# MODEL_PROVIDER=anthropic
# ANTHROPIC_API_KEY=

# OPTION 4: Free/Local options
# MODEL=llama3.1:8b
# MODEL_PROVIDER=ollama
# (Requires Ollama to be installed and running locally)

# OPTION 5: Groq (Fast and often has free tier)
# MODEL=llama-3.1-70b-versatile
# MODEL_PROVIDER=groq
# GROQ_API_KEY=

# OPTION 6: Pollinations (Free, OpenAI-compatible)
# MODEL=openai
# MODEL_PROVIDER=pollinations
# POLLINATIONS_API_KEY=your_pollinations_api_key_here  # Optional
# POLLINATIONS_REFERRER=openoperator-v1  # Optional
# Note: No API key required - completely free! But API key provides higher rate limits.

# OPTION 7: Groq (Fast and often has free tier) - RECOMMENDED FOR TESTING
# MODEL=llama-3.1-70b-versatile
# MODEL_PROVIDER=groq
# GROQ_API_KEY=your_groq_api_key_here

# Be default, Langchain tracing is enabled. Set keys and project name to make it track your requests. Feel free to disable it if you don't want to track your requests.
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=

# LogLevel: Set to debug to enable verbose logging, set to result to get results only. Available: result | debug | info
BROWSER_USE_LOGGING_LEVEL=info

# Pollinations AI Configuration (optional)
# These are for the vision and text generation tools, NOT the main LLM
# Optional: For referrer-based authentication
POLLINATIONS_REFERRER=openoperator-v1
# Optional: Pollinations API key for enhanced features (higher rate limits, priority access)
POLLINATIONS_API_KEY=

# When using Pollinations as main LLM provider, you can also set the API key here
# This will be used for authentication with the OpenAI-compatible endpoint
# POLLINATIONS_API_KEY=your_pollinations_api_key_here
